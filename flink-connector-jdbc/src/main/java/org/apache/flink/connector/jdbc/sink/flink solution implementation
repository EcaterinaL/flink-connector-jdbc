import com.mongodb.MongoClient;
import com.mongodb.client.MongoCollection;
import com.mongodb.client.MongoDatabase;
import com.mongodb.client.model.UpdateOptions;
import org.apache.flink.api.common.state.MapState;
import org.apache.flink.api.common.state.MapStateDescriptor;
import org.apache.flink.api.common.typeinfo.Types;
import org.apache.flink.configuration.Configuration;
import org.apache.flink.streaming.api.functions.sink.RichSinkFunction;
import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;
import org.apache.flink.streaming.api.functions.RichFlatMapFunction;
import org.apache.flink.util.Collector;
import org.apache.flink.api.java.tuple.Tuple3;
import org.bson.Document;

import java.security.MessageDigest;
import java.security.NoSuchAlgorithmException;
import java.util.Map;

public class FlinkDeltaComparison {

    public static void main(String[] args) throws Exception {
        // Initialize Flink execution environment
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        // Step 1: Read source data (Simulated JDBC source)
        DataStream<Tuple3<String, String, String>> sourceStream = env.addSource(new SourceSimulator());

        // Step 2: Perform delta comparison with MongoDB
        DataStream<DeltaRecord> deltaStream = sourceStream.flatMap(new DeltaComparisonFunction());

        // Step 3: Write to MongoDB
        deltaStream.addSink(new MongoDBSink());

        // Execute the Flink job
        env.execute("Flink Delta Comparison Job");
    }

    /**
     * Step 1: Simulate reading from Oracle/Snowflake
     */
    public static class SourceSimulator extends RichParallelSourceFunction<Tuple3<String, String, String>> {
        private boolean running = true;

        @Override
        public void run(SourceContext<Tuple3<String, String, String>> ctx) throws Exception {
            // Simulate incoming data
            while (running) {
                ctx.collect(new Tuple3<>("1", "value1", "value2"));
                Thread.sleep(1000);
            }
        }

        @Override
        public void cancel() {
            running = false;
        }
    }

    /**
     * Step 2: Delta Comparison with MongoDB
     */
    public static class DeltaComparisonFunction extends RichFlatMapFunction<Tuple3<String, String, String>, DeltaRecord> {
        private transient MongoClient mongoClient;
        private transient MongoCollection<Document> collection;
        private transient MapState<String, String> stateCache;

        @Override
        public void open(Configuration parameters) throws Exception {
            // Initialize MongoDB client
            mongoClient = new MongoClient("localhost", 27017);
            MongoDatabase database = mongoClient.getDatabase("target_db");
            collection = database.getCollection("A_mongo");

            // Initialize state cache
            MapStateDescriptor<String, String> stateDescriptor =
                    new MapStateDescriptor<>("mongo-state", Types.STRING, Types.STRING);
            stateCache = getRuntimeContext().getMapState(stateDescriptor);

            // Load initial MongoDB state into the cache
            for (Document doc : collection.find()) {
                String id = doc.getString("_id");
                String hash = doc.getString("hash");
                stateCache.put(id, hash);
            }
        }

        @Override
        public void flatMap(Tuple3<String, String, String> sourceRecord, Collector<DeltaRecord> out) throws Exception {
            String id = sourceRecord.f0;
            String value1 = sourceRecord.f1;
            String value2 = sourceRecord.f2;

            // Compute hash for the incoming record
            String sourceHash = computeHash(value1 + value2);

            // Get the existing hash from state cache
            String existingHash = stateCache.get(id);

            if (existingHash == null) {
                // New record: Insert
                out.collect(new DeltaRecord(id, value1, value2, DeltaType.INSERT));
                stateCache.put(id, sourceHash);
            } else if (!existingHash.equals(sourceHash)) {
                // Modified record: Update
                out.collect(new DeltaRecord(id, value1, value2, DeltaType.UPDATE));
                stateCache.put(id, sourceHash);
            }
        }

        @Override
        public void close() throws Exception {
            if (mongoClient != null) {
                mongoClient.close();
            }
        }

        private String computeHash(String value) throws NoSuchAlgorithmException {
            MessageDigest md = MessageDigest.getInstance("MD5");
            byte[] hashBytes = md.digest(value.getBytes());
            StringBuilder hash = new StringBuilder();
            for (byte b : hashBytes) {
                hash.append(String.format("%02x", b));
            }
            return hash.toString();
        }
    }

    /**
     * Step 3: Write Changes to MongoDB
     */
    public static class MongoDBSink extends RichSinkFunction<DeltaRecord> {
        private transient MongoClient mongoClient;
        private transient MongoCollection<Document> collection;

        @Override
        public void open(Configuration parameters) throws Exception {
            mongoClient = new MongoClient("localhost", 27017);
            MongoDatabase database = mongoClient.getDatabase("target_db");
            collection = database.getCollection("A_mongo");
        }

        @Override
        public void invoke(DeltaRecord record, Context context) throws Exception {
            if (record.getDeltaType() == DeltaType.INSERT) {
                // Insert new record
                Document doc = new Document("_id", record.getId())
                        .append("value1", record.getValue1())
                        .append("value2", record.getValue2())
                        .append("hash", computeHash(record.getValue1() + record.getValue2()));
                collection.insertOne(doc);
            } else if (record.getDeltaType() == DeltaType.UPDATE) {
                // Update existing record
                collection.updateOne(
                        new Document("_id", record.getId()),
                        new Document("$set", new Document("value1", record.getValue1())
                                .append("value2", record.getValue2())
                                .append("hash", computeHash(record.getValue1() + record.getValue2()))),
                        new UpdateOptions().upsert(true));
            }
        }

        @Override
        public void close() throws Exception {
            if (mongoClient != null) {
                mongoClient.close();
            }
        }

        private String computeHash(String value) throws NoSuchAlgorithmException {
            MessageDigest md = MessageDigest.getInstance("MD5");
            byte[] hashBytes = md.digest(value.getBytes());
            StringBuilder hash = new StringBuilder();
            for (byte b : hashBytes) {
                hash.append(String.format("%02x", b));
            }
            return hash.toString();
        }
    }

    /**
     * Delta Record Class
     */
    public static class DeltaRecord {
        private String id;
        private String value1;
        private String value2;
        private DeltaType deltaType;

        public DeltaRecord(String id, String value1, String value2, DeltaType deltaType) {
            this.id = id;
            this.value1 = value1;
            this.value2 = value2;
            this.deltaType = deltaType;
        }

        public String getId() {
            return id;
        }

        public String getValue1() {
            return value1;
        }

        public String getValue2() {
            return value2;
        }

        public DeltaType getDeltaType() {
            return deltaType;
        }
    }

    /**
     * Delta Type Enum
     */
    public enum DeltaType {
        INSERT,
        UPDATE
    }
}
